{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from transformers import AutoTokenizer\n",
    "from transformers import T5ForConditionalGeneration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TextGenerate:\n",
    "    def __init__(self, model):\n",
    "        self.tokenizer = AutoTokenizer.from_pretrained(model)\n",
    "        self.model = T5ForConditionalGeneration.from_pretrained(model)\n",
    "\n",
    "    def encode_text(self, text_input, text_ouput):\n",
    "        inputs = self.tokenizer(\n",
    "            text_input,\n",
    "            max_length=16,\n",
    "            truncation=True,\n",
    "            padding=\"max_length\",\n",
    "            return_tensors=\"pt\",\n",
    "        )\n",
    "        labels = self.tokenizer(\n",
    "            text_ouput,\n",
    "            max_length=16,\n",
    "            truncation=True,\n",
    "            padding=\"max_length\",\n",
    "            return_tensors=\"pt\",\n",
    "        ).input_ids[0]\n",
    "        input_ids = inputs[\"input_ids\"][0]\n",
    "        attention_mask = inputs[\"attention_mask\"][0]\n",
    "        labels = torch.tensor([label if label != 0 else -100 for label in labels])\n",
    "        return {\n",
    "            \"input_ids\": input_ids,\n",
    "            \"attention_mask\": attention_mask,\n",
    "            \"labels\": labels,\n",
    "        }\n",
    "\n",
    "    def generate_prediction(\n",
    "        self, ctext, summ_len=16, beam_search=10, repetition_penalty=2.5\n",
    "    ):\n",
    "        input_ids = self.tokenizer(ctext, return_tensors=\"pt\").input_ids\n",
    "\n",
    "        generated_ids = self.model.generate(\n",
    "            input_ids,\n",
    "            do_sample=True,\n",
    "            max_length=summ_len,\n",
    "            top_k=beam_search,\n",
    "            temperature=0.7,\n",
    "        )\n",
    "\n",
    "        summary = self.tokenizer.decode(\n",
    "            generated_ids.squeeze(),\n",
    "            skip_special_tokens=True,\n",
    "            repetition_penalty=repetition_penalty,\n",
    "        )\n",
    "        return summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "custom_model = TextGenerate('shaankhosla/digit_conversion')\n",
    "output = custom_model.generate_prediction(\"5\")\n",
    "print(output)\n",
    "output = custom_model.generate_prediction(\"-8\")\n",
    "print(output)\n",
    "output = custom_model.generate_prediction(\"11\")\n",
    "print(output)\n",
    "output = custom_model.generate_prediction(\"24\")\n",
    "print(output)\n",
    "output = custom_model.generate_prediction(\"-112\")\n",
    "print(output)\n",
    "output = custom_model.generate_prediction(\"-236\")\n",
    "print(output)\n",
    "output = custom_model.generate_prediction(\"-7965\")\n",
    "print(output)\n",
    "output = custom_model.generate_prediction(\"32043\")\n",
    "print(output)\n",
    "output = custom_model.generate_prediction(\"34986\")\n",
    "print(output)\n",
    "output = custom_model.generate_prediction(\"430895\")\n",
    "print(output)\n",
    "output = custom_model.generate_prediction(\"435641\")\n",
    "print(output)\n",
    "output = custom_model.generate_prediction(\"-43968\")\n",
    "print(output)\n",
    "output = custom_model.generate_prediction(\"-328493\")\n",
    "print(output)\n",
    "output = custom_model.generate_prediction(\"-352501\")\n",
    "print(output)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nlp-with-llms-sfgRzLAF-py3.9",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
